{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "from abandabot.evaluate import evaluate_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"reports/performance.json\") as f:\n",
    "    perf = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "context",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "macro_precision",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "macro_recall",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "macro_f1",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "7829b58b-9f36-401c-a40d-b3c3686aab88",
       "rows": [
        [
         "0",
         "gpt-4o",
         "reasoning",
         "0.739±0.039",
         "0.618±0.027",
         "0.623±0.036"
        ],
        [
         "1",
         "gpt-4o",
         "reasoning+theory",
         "0.709±0.069",
         "0.601±0.047",
         "0.599±0.065"
        ],
        [
         "2",
         "gpt-4o",
         "context+reasoning",
         "0.672±0.037",
         "0.657±0.039",
         "0.661±0.039"
        ],
        [
         "3",
         "gpt-4o",
         "context+reasoning+theory",
         "0.743±0.047",
         "0.752±0.045",
         "0.746±0.046"
        ],
        [
         "4",
         "deepseek-v3",
         "reasoning",
         "0.753±0.049",
         "0.581±0.025",
         "0.566±0.038"
        ],
        [
         "5",
         "deepseek-v3",
         "reasoning+theory",
         "0.772±0.094",
         "0.625±0.052",
         "0.632±0.065"
        ],
        [
         "6",
         "deepseek-v3",
         "context+reasoning",
         "0.641±0.032",
         "0.655±0.036",
         "0.643±0.034"
        ],
        [
         "7",
         "deepseek-v3",
         "context+reasoning+theory",
         "0.739±0.027",
         "0.772±0.030",
         "0.746±0.029"
        ],
        [
         "8",
         "llama-v3p3",
         "reasoning",
         "0.798±0.099",
         "0.541±0.020",
         "0.495±0.035"
        ],
        [
         "9",
         "llama-v3p3",
         "reasoning+theory",
         "0.734±0.058",
         "0.603±0.029",
         "0.602±0.038"
        ],
        [
         "10",
         "llama-v3p3",
         "context+reasoning",
         "0.674±0.018",
         "0.618±0.012",
         "0.626±0.013"
        ],
        [
         "11",
         "llama-v3p3",
         "context+reasoning+theory",
         "0.740±0.040",
         "0.678±0.032",
         "0.693±0.035"
        ],
        [
         "12",
         "gemini-2.0",
         "reasoning",
         "0.398±0.159",
         "0.502±0.006",
         "0.414±0.013"
        ],
        [
         "13",
         "gemini-2.0",
         "reasoning+theory",
         "0.532±0.192",
         "0.514±0.030",
         "0.451±0.053"
        ],
        [
         "14",
         "gemini-2.0",
         "context+reasoning",
         "0.860±0.026",
         "0.591±0.010",
         "0.578±0.016"
        ],
        [
         "15",
         "gemini-2.0",
         "context+reasoning+theory",
         "0.805±0.064",
         "0.627±0.027",
         "0.633±0.035"
        ],
        [
         "16",
         "yesman",
         "yesman",
         "0.3475609756097561",
         "0.5",
         "0.41007194244604317"
        ],
        [
         "17",
         "noman",
         "noman",
         "0.1524390243902439",
         "0.5",
         "0.2336448598130841"
        ],
        [
         "18",
         "random",
         "random",
         "0.5",
         "0.5",
         "0.5"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 19
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>context</th>\n",
       "      <th>macro_precision</th>\n",
       "      <th>macro_recall</th>\n",
       "      <th>macro_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>0.739±0.039</td>\n",
       "      <td>0.618±0.027</td>\n",
       "      <td>0.623±0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>reasoning+theory</td>\n",
       "      <td>0.709±0.069</td>\n",
       "      <td>0.601±0.047</td>\n",
       "      <td>0.599±0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>context+reasoning</td>\n",
       "      <td>0.672±0.037</td>\n",
       "      <td>0.657±0.039</td>\n",
       "      <td>0.661±0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>context+reasoning+theory</td>\n",
       "      <td>0.743±0.047</td>\n",
       "      <td>0.752±0.045</td>\n",
       "      <td>0.746±0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deepseek-v3</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>0.753±0.049</td>\n",
       "      <td>0.581±0.025</td>\n",
       "      <td>0.566±0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>deepseek-v3</td>\n",
       "      <td>reasoning+theory</td>\n",
       "      <td>0.772±0.094</td>\n",
       "      <td>0.625±0.052</td>\n",
       "      <td>0.632±0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>deepseek-v3</td>\n",
       "      <td>context+reasoning</td>\n",
       "      <td>0.641±0.032</td>\n",
       "      <td>0.655±0.036</td>\n",
       "      <td>0.643±0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>deepseek-v3</td>\n",
       "      <td>context+reasoning+theory</td>\n",
       "      <td>0.739±0.027</td>\n",
       "      <td>0.772±0.030</td>\n",
       "      <td>0.746±0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>llama-v3p3</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>0.798±0.099</td>\n",
       "      <td>0.541±0.020</td>\n",
       "      <td>0.495±0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>llama-v3p3</td>\n",
       "      <td>reasoning+theory</td>\n",
       "      <td>0.734±0.058</td>\n",
       "      <td>0.603±0.029</td>\n",
       "      <td>0.602±0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>llama-v3p3</td>\n",
       "      <td>context+reasoning</td>\n",
       "      <td>0.674±0.018</td>\n",
       "      <td>0.618±0.012</td>\n",
       "      <td>0.626±0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>llama-v3p3</td>\n",
       "      <td>context+reasoning+theory</td>\n",
       "      <td>0.740±0.040</td>\n",
       "      <td>0.678±0.032</td>\n",
       "      <td>0.693±0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gemini-2.0</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>0.398±0.159</td>\n",
       "      <td>0.502±0.006</td>\n",
       "      <td>0.414±0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gemini-2.0</td>\n",
       "      <td>reasoning+theory</td>\n",
       "      <td>0.532±0.192</td>\n",
       "      <td>0.514±0.030</td>\n",
       "      <td>0.451±0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gemini-2.0</td>\n",
       "      <td>context+reasoning</td>\n",
       "      <td>0.860±0.026</td>\n",
       "      <td>0.591±0.010</td>\n",
       "      <td>0.578±0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gemini-2.0</td>\n",
       "      <td>context+reasoning+theory</td>\n",
       "      <td>0.805±0.064</td>\n",
       "      <td>0.627±0.027</td>\n",
       "      <td>0.633±0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>yesman</td>\n",
       "      <td>yesman</td>\n",
       "      <td>0.347561</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.410072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>noman</td>\n",
       "      <td>noman</td>\n",
       "      <td>0.152439</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.233645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>random</td>\n",
       "      <td>random</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model                   context macro_precision macro_recall  \\\n",
       "0        gpt-4o                 reasoning     0.739±0.039  0.618±0.027   \n",
       "1        gpt-4o          reasoning+theory     0.709±0.069  0.601±0.047   \n",
       "2        gpt-4o         context+reasoning     0.672±0.037  0.657±0.039   \n",
       "3        gpt-4o  context+reasoning+theory     0.743±0.047  0.752±0.045   \n",
       "4   deepseek-v3                 reasoning     0.753±0.049  0.581±0.025   \n",
       "5   deepseek-v3          reasoning+theory     0.772±0.094  0.625±0.052   \n",
       "6   deepseek-v3         context+reasoning     0.641±0.032  0.655±0.036   \n",
       "7   deepseek-v3  context+reasoning+theory     0.739±0.027  0.772±0.030   \n",
       "8    llama-v3p3                 reasoning     0.798±0.099  0.541±0.020   \n",
       "9    llama-v3p3          reasoning+theory     0.734±0.058  0.603±0.029   \n",
       "10   llama-v3p3         context+reasoning     0.674±0.018  0.618±0.012   \n",
       "11   llama-v3p3  context+reasoning+theory     0.740±0.040  0.678±0.032   \n",
       "12   gemini-2.0                 reasoning     0.398±0.159  0.502±0.006   \n",
       "13   gemini-2.0          reasoning+theory     0.532±0.192  0.514±0.030   \n",
       "14   gemini-2.0         context+reasoning     0.860±0.026  0.591±0.010   \n",
       "15   gemini-2.0  context+reasoning+theory     0.805±0.064  0.627±0.027   \n",
       "16       yesman                    yesman        0.347561          0.5   \n",
       "17        noman                     noman        0.152439          0.5   \n",
       "18       random                    random             0.5          0.5   \n",
       "\n",
       "       macro_f1  \n",
       "0   0.623±0.036  \n",
       "1   0.599±0.065  \n",
       "2   0.661±0.039  \n",
       "3   0.746±0.046  \n",
       "4   0.566±0.038  \n",
       "5   0.632±0.065  \n",
       "6   0.643±0.034  \n",
       "7   0.746±0.029  \n",
       "8   0.495±0.035  \n",
       "9   0.602±0.038  \n",
       "10  0.626±0.013  \n",
       "11  0.693±0.035  \n",
       "12  0.414±0.013  \n",
       "13  0.451±0.053  \n",
       "14  0.578±0.016  \n",
       "15  0.633±0.035  \n",
       "16     0.410072  \n",
       "17     0.233645  \n",
       "18          0.5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = []\n",
    "for setting, perf_logs in perf.items():\n",
    "    model = setting.split(\"+\")[0]\n",
    "    context = \"+\".join(setting.split(\"+\")[1:])\n",
    "    avg_perf = pd.DataFrame(perf_logs).mean()\n",
    "    std_pref = pd.DataFrame(perf_logs).std()\n",
    "    results = {\"model\": model, \"context\": context}\n",
    "    for key in avg_perf.keys():\n",
    "        results[key] = f\"{avg_perf[key]:.3f}±{std_pref[key]:.3f}\"\n",
    "    table.append(results)\n",
    "\n",
    "ground_truth = pd.read_csv(\"ground_truth.csv\")\n",
    "ground_truth = ground_truth[ground_truth.impactful.isin((\"Yes\", \"No\"))]\n",
    "\n",
    "table.append(\n",
    "    {\n",
    "        \"model\": \"yesman\",\n",
    "        \"context\": \"yesman\",\n",
    "        **evaluate_performance(\n",
    "            ground_truth.impactful, [\"Yes\"] * len(ground_truth), \"Yes\", \"No\"\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "table.append(\n",
    "    {\n",
    "        \"model\": \"noman\",\n",
    "        \"context\": \"noman\",\n",
    "        **evaluate_performance(\n",
    "            ground_truth.impactful, [\"No\"] * len(ground_truth), \"Yes\", \"No\"\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "\n",
    "table.append(\n",
    "    {\n",
    "        \"model\": \"random\",\n",
    "        \"context\": \"random\",\n",
    "        \"errors\": 0,\n",
    "        \"macro_precision\": 0.5,\n",
    "        \"macro_recall\": 0.5,\n",
    "        \"macro_f1\": 0.5,\n",
    "    }\n",
    ")\n",
    "\n",
    "table = pd.DataFrame(table)\n",
    "table[\"model context macro_precision macro_recall macro_f1\".split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "context",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "errors",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "yes_precision",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "yes_recall",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "yes_f1",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "no_precision",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "no_recall",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "no_f1",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "macro_precision",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "macro_recall",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "macro_f1",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "5d4886a0-0258-4361-88f7-288535974bbf",
       "rows": [
        [
         "3",
         "gpt-4o",
         "context+reasoning+theory",
         "1.200±1.398",
         "0.857±0.029",
         "0.825±0.045",
         "0.840±0.031",
         "0.628±0.072",
         "0.679±0.072",
         "0.651±0.062",
         "0.743±0.047",
         "0.752±0.045",
         "0.746±0.046"
        ],
        [
         "7",
         "deepseek-v3",
         "context+reasoning+theory",
         "0.000±0.000",
         "0.889±0.022",
         "0.760±0.031",
         "0.819±0.023",
         "0.590±0.037",
         "0.784±0.047",
         "0.672±0.036",
         "0.739±0.027",
         "0.772±0.030",
         "0.746±0.029"
        ],
        [
         "11",
         "llama-v3p3",
         "context+reasoning+theory",
         "0.000±0.000",
         "0.789±0.018",
         "0.912±0.022",
         "0.846±0.018",
         "0.690±0.064",
         "0.444±0.051",
         "0.540±0.054",
         "0.740±0.040",
         "0.678±0.032",
         "0.693±0.035"
        ],
        [
         "15",
         "gemini-2.0",
         "context+reasoning+theory",
         "0.000±0.000",
         "0.755±0.013",
         "0.977±0.020",
         "0.852±0.013",
         "0.854±0.122",
         "0.276±0.048",
         "0.414±0.060",
         "0.805±0.064",
         "0.627±0.027",
         "0.633±0.035"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>context</th>\n",
       "      <th>errors</th>\n",
       "      <th>yes_precision</th>\n",
       "      <th>yes_recall</th>\n",
       "      <th>yes_f1</th>\n",
       "      <th>no_precision</th>\n",
       "      <th>no_recall</th>\n",
       "      <th>no_f1</th>\n",
       "      <th>macro_precision</th>\n",
       "      <th>macro_recall</th>\n",
       "      <th>macro_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>context+reasoning+theory</td>\n",
       "      <td>1.200±1.398</td>\n",
       "      <td>0.857±0.029</td>\n",
       "      <td>0.825±0.045</td>\n",
       "      <td>0.840±0.031</td>\n",
       "      <td>0.628±0.072</td>\n",
       "      <td>0.679±0.072</td>\n",
       "      <td>0.651±0.062</td>\n",
       "      <td>0.743±0.047</td>\n",
       "      <td>0.752±0.045</td>\n",
       "      <td>0.746±0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>deepseek-v3</td>\n",
       "      <td>context+reasoning+theory</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.889±0.022</td>\n",
       "      <td>0.760±0.031</td>\n",
       "      <td>0.819±0.023</td>\n",
       "      <td>0.590±0.037</td>\n",
       "      <td>0.784±0.047</td>\n",
       "      <td>0.672±0.036</td>\n",
       "      <td>0.739±0.027</td>\n",
       "      <td>0.772±0.030</td>\n",
       "      <td>0.746±0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>llama-v3p3</td>\n",
       "      <td>context+reasoning+theory</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.789±0.018</td>\n",
       "      <td>0.912±0.022</td>\n",
       "      <td>0.846±0.018</td>\n",
       "      <td>0.690±0.064</td>\n",
       "      <td>0.444±0.051</td>\n",
       "      <td>0.540±0.054</td>\n",
       "      <td>0.740±0.040</td>\n",
       "      <td>0.678±0.032</td>\n",
       "      <td>0.693±0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gemini-2.0</td>\n",
       "      <td>context+reasoning+theory</td>\n",
       "      <td>0.000±0.000</td>\n",
       "      <td>0.755±0.013</td>\n",
       "      <td>0.977±0.020</td>\n",
       "      <td>0.852±0.013</td>\n",
       "      <td>0.854±0.122</td>\n",
       "      <td>0.276±0.048</td>\n",
       "      <td>0.414±0.060</td>\n",
       "      <td>0.805±0.064</td>\n",
       "      <td>0.627±0.027</td>\n",
       "      <td>0.633±0.035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model                   context       errors yes_precision  \\\n",
       "3        gpt-4o  context+reasoning+theory  1.200±1.398   0.857±0.029   \n",
       "7   deepseek-v3  context+reasoning+theory  0.000±0.000   0.889±0.022   \n",
       "11   llama-v3p3  context+reasoning+theory  0.000±0.000   0.789±0.018   \n",
       "15   gemini-2.0  context+reasoning+theory  0.000±0.000   0.755±0.013   \n",
       "\n",
       "     yes_recall       yes_f1 no_precision    no_recall        no_f1  \\\n",
       "3   0.825±0.045  0.840±0.031  0.628±0.072  0.679±0.072  0.651±0.062   \n",
       "7   0.760±0.031  0.819±0.023  0.590±0.037  0.784±0.047  0.672±0.036   \n",
       "11  0.912±0.022  0.846±0.018  0.690±0.064  0.444±0.051  0.540±0.054   \n",
       "15  0.977±0.020  0.852±0.013  0.854±0.122  0.276±0.048  0.414±0.060   \n",
       "\n",
       "   macro_precision macro_recall     macro_f1  \n",
       "3      0.743±0.047  0.752±0.045  0.746±0.046  \n",
       "7      0.739±0.027  0.772±0.030  0.746±0.029  \n",
       "11     0.740±0.040  0.678±0.032  0.693±0.035  \n",
       "15     0.805±0.064  0.627±0.027  0.633±0.035  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table[table.context == \"context+reasoning+theory\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abandabot-L22U2UfH-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
